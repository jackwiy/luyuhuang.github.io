---
title: 分布式哈希表 (DHT) 和 p2p 技术
category: design
featured: true
---
## 1. 引言
相信没有人没使用过 p2p 技术. BT 种子和磁力链接就是最常见的 p2p 技术, 使用 p2p 技术, 文件不再需要集中存储在一台服务器(或一个集群)上, 而是分散再各个用户的节点上, 每个人都是服务的提供者, 也是服务的使用者. 这样的系统具有高可用性, 不会由于一两台机的宕机而导致整个服务不可用. 那么这样一个系统是怎样实现的, 如何做到**去中心化(decentralization)**和**自我组织(self-organization)**的呢? 这篇文章我们来讨论一下这个问题.

这篇文章先会介绍 p2p 网络的整体思路, 并引出 p2p 网络的主角 - **分布式哈希表(Distributed Hash Table, DHT)**; 接着会介绍两种分布式哈希表算法. 这些会让你对 p2p 技术有一个较为具体的了解.

## 2. p2p 网络的概述

### 2.1 传统 CS 网络和 p2p 网络

CS 架构即 Client-Server 架构, 由服务器和客户端组成: 服务器为服务的提供者, 客户端为服务的使用者. 我们如今使用的很多应用程序例如网盘, 视频应用, 网购平台等都是 CS 架构. 它的架构如下图所示:

![cs]()

当然服务器通常不是一个单点, 往往是一个集群; 但本质上是一样的. CS 架构的问题在于, 一旦服务器关闭, 例如宕机, 被 DDos 攻击或者被查水表, 客户端就无法使用了, 服务也就失效了.

为了解决这个问题, 人们提出了 **p2p 网络(Peer-to-peer Networking)**. 在 p2p 网络中, 不再由中心服务器提供服务, 不再有"服务器"的概念, 每个人即使服务的提供者也是服务的使用者 -- i.e., 每个人都有可能是服务器. 我们常用的 BT 种子和磁力链接下载服务就是 p2p 架构. 人们对 p2p 系统作了如下定义:

> **a Peer-to-Peer system** is a self-organizing system of equal, autonomous entities (peers) **which** aims for the shared usage of distributed resources in a networked environment avoiding central services.

一个 p2p 系统是每个节点都是平等, 自主的一个自我组织的系统, 目的是在避免中心服务的网络环境中共享使用分布式资源.

![p2p]()

p2p 系统的架构如上图所示. 由于去掉了中心服务器, p2p 系统的稳定性就强很多: 少数几个个节点的失效几乎不会影响整个服务; 节点多为用户提供, 可以做到 "野火烧不尽, 春风吹又生". 即使有人想恶意破坏, 也无法对整个系统造成有效打击.

### 2.2 朴素的 p2p 网络

p2p 网络需要解决的一个最重要的问题就是, 如何知道用户请求的资源位于哪个节点上. 在第一代 p2p 网络中, 人们设置了一台中央服务器来管理资源所处的位置. 当一个用户想要发布资源, 他需要告诉中央服务器它发布的资源信息和自己的节点信息; 当其他用户请求资源的时候, 需要先请求中央服务器以获取资源发布者的节点信息, 再向资源发布者请求资源.

![central-server]()

这种 p2p 网络的好处是效率高, 只需要请求一次中央服务器就可以发布或获取资源. 然而它的缺点也很明显: 中央服务器是这个网络系统最脆弱的地方, 它需要存储所有资源的信息, 处理所有节点的请求; 一旦中央服务器失效, 整个网络就无法使用.

早期的另外一种 p2p 网络采取了不同的策略, 它不设置中央服务器; 当用户请求资源时, 它会请求它所有的邻接节点, 邻接节点再以此请求各自的邻接节点, 并使用一些策略防止重复请求, 直到找到拥有资源的节点. i.e. 这是一种泛洪搜索(Flooding Search).

![flooding-search]()

这种 p2p 网络去除了中央服务器, 它的稳定性就强多了. 然而它太慢了. 一次查找可能会产生大量的请求, 可能会有大量的节点卷入其中. 一旦整个系统中的的节点过多, 可用性就会变得很差.

### 2.3 分布式哈希表

为了解决这些问题, 分布式哈希表应运而生. 在一个有 $n$ 个节点的分布式哈希表中, 每个节点仅需存储 $\mathrm{O}(\log n)$ 个其他节点, 查找资源时仅需请求 $\mathrm{O}(\log n)$ 个节点, 并且无需中央服务器, 是一个完全自组织的系统. 分布式哈希表有很多中实现算法, 第 3 节和第 4 节会详细介绍其中的两种. 这里我们先来看看它们共通的思想.

#### 地址管理

首先, 在分布式哈希表中, 每个节点都有一个唯一的 ID, 每个发布的资源也有一个唯一的 Key. 节点 ID 和资源 Key 的空间是一样的, 通常都是一个 160 位的整数. 我们可以把一个节点的 ip 地址用 sha1 算法哈希得到这个节点的 ID; 同样地, 把一个资源文件用 sha1 算法哈希就能得到这个资源的 Key 了.

定义好 ID 和 Key 之后, 就可以发布和存储资源了. 每个节点都会负责一段特定范围的 Key, 其规则取决于具体的算法. 例如, 在 Chord 算法中, 每个 Key 总是被第一个有着比它大的 ID 的节点负责. 在发布资源的的时候, 先通过哈希算法计算出资源文件的 Key, 然后联系负责这个 Key 的节点, 把文件存放在这个节点上. 当有人请求资源的时候, 就联系负责这个 Key 的节点, 把文件取回即可.

发布和请求资源有两种做法, 一种是直接把文件传输给负责的节点, 由它存储文件资源; 然后再由这个节点将文件传输给请求者. 另一种做法是由发布者自己设法存储资源, 发布文件时把文件所在节点的地址传输给负责的节点, 负责的节点仅存储一个地址; 请求资源的时候会联系负责的节点获取资源文件的地址, 然后在取回资源. 这两种做法各有优劣. 前者的好处是资源的发布者不必在线, 请求者也能获取资源; 坏处是如果文件过大, 就会产生较大的传输和存储成本. 后者的好处是传输和存储成本都比较小, 但是资源的发布者, 或者说资源文件所在的节点必须一直在线.

#### 路由算法

上面我们简述了地址系统, 以及如何发布和取回资源. 但是现在还有一个大问题: 如何找到负责某个特定 Key 的节点呢? 这里就要用到路由算法了. 不同的分布式哈希表实现有不同的路由算法, 但它们的思路是一致的.

首先每个节点会由若干个其他节点的联系方式(IP 地址, 端口), 称之为路由表. 一般来说一个有着 $n$ 个节点的分布式哈希表中, 一个节点的路由表的长度为 $\mathrm{O}(\log{n})$. 每个节点都会按照特定的规则构建路由表, 最终所有的节点会形成一张网络. 从一个节点发出的消息会根据特定的路由规则, 沿着网络逐步接近目标节点, 最终达到目标节点. 在有着 $n$ 个节点的分布式哈希表中, 这个过程的转发次数为 $\mathrm{O}(\log{n})$ 次.

#### 自我组织(self-organization)

分布式哈希表中的节点都是由各个用户组成, 随时有用户加入, 离开或失效; 并且分布式哈希表没有中央服务器, 也就是说着这个系统完全没有管理者. 这意味着分配地址, 构建路由表, 节点加入, 节点离开, 排除失效节点等操作都要靠自我组织策略实现.

## 3. Chord 算法

上一节简单介绍了 p2p 网络和分布式哈希表, 现在我们来讨论它的一个具体实现. 分布式哈希表有很多中实现, Ion Stoica 和 Robert Morris 等人在 2001 年的一篇论文中提出了 Chord 算法, 原论文已在文章末尾的参考资料中给出.

## 4. Kademlia 算法

Petar Maymounkov 和 David Mazières 在 2002 年的一篇论文中提出了 Kademlia 算法, 原论文已在文章末尾的参考资料中给出.

## 5. 总结

---

**参考资料**
- [Peer-to-Peer Systems and Applications](https://www.springer.com/us/book/9783540291923)
- [Chord: A scalable peer-to-peer lookup service for internet applications](https://dl.acm.org/doi/abs/10.1145/964723.383071)
- [Kademlia: A Peer-to-Peer Information System Based on the XOR Metric](https://link.springer.com/chapter/10.1007/3-540-45748-8_5)
